#!/usr/bin/env python
# encoding: utf-8

from __future__ import print_function, division
import subprocess
import os
import tempfile
import sys
import re
import os
import glob
import math


class CommandError(Exception):
    """There was an error in calling the command."""
    
    def __init__(self, function=None, error=None, *hints):
        if function is None:
            function = "unknown function"
        if error is None:
            error = "unspecified"
        msg = "Error '%s' occured in %s" % (error, function)
        super(CommandError, self).__init__(msg)
        self.function = function
        self.error    = error
        self.hints    = hints
        self.report   = (error,) + hints


class CommandFailed(Exception):
    """A command has failed to carry out fully."""

    def __init__(self, function=None, error=None, *hints):
        if function is None:
            function = "unknown function"
        if error is None:
            error = "unspecified"
        msg = "Error '%s' occured in %s" % (error, function)
        super(CommandFailed, self).__init__(msg)
        self.function = function
        self.error    = error
        self.hints    = hints
        self.report   = (error,) + hints


def schedule(command=None, script=None, settings=None, replace=None, workdir=None, environment=None, output=None):
    '''
    schedule [command=<command string>] [script=<path to script>] \\
             settings=<settings string> \\
             [replace=<"key:value|key:value" string>] \\
             [workdir=<path to working directory>] \\
             [environment=<path to environment setup script>] \\
             [output=<string specifying how to process output>]

    USE
    ===

    Schedules the provided command the referenced script to be run by the
    specified scheduler (PBS, LSF, SLURM are currently supported).

    PARAMETERS
    ==========

    Required parameters
    -------------------

    To run successfully, both one of the following has to be provided:

    --command   The string to be executed. It can be a single command or a
                complex multiline script.
    --script    The path to a script to be executed.

    as well the settings need to be specified by:

    --settings  A string specifying the scheduler to be used and the additional
                settings for it.

    Settings string should be a comma separated list of parameters. The first
    parameter has to be the scheduler name (PBS, LSF, SLURM), the rest of the
    parameters are key-value pairs that are to be passed as settings to the
    scheduler. Additional parameters common to all the schedulers can be
    specified:

    * jobname  - the name of the job to run
    * comname  - the name of the command the job runs
    * jobnum   - the number of the job being run

    Example settings strings:

    "SLURM,jobname=bet1,time=03-24:00:00,ntasks=10,cpus-per-task=2,mem-per-cpu=2500,partition=pi_anticevic"
    "LSF,jobname=DWIproc,jobnum=1,cores=20,mem=250000,walltime=650:00,queue=anticevic"

    Optional parameters
    -------------------

    --replace       A string of key-value pairs that specify the specific values
                    to be imputed into the script or command.
    --workdir       A path to the working directory in which the command or
                    script is to be executed.
    --environment   A path to a script to be executed before all other commands
                    to set up the environment for execution.
    --output        A string specifying whether to return or redirect the
                    standard output and error. See "REDIRECTING OUTPUT" for
                    details

    If the optional parameters are not specified, they will not be used.

    VALUE EMBEDDING
    ===============

    If replace parameter is set, all instances of {{key}} in the command or
    script will be replaced with the provided value. The key/value pairs need
    to be separated by pipe characted, whereas key and value need to be
    separated by a colon. An example replacement string:

    "subject:AP23791|folder:/studies/WM/Subjects/AP23791"

    REDIRECTING OUTPUT
    ==================

    If no output is specified, the job's standard output and error (stdout,
    stderr) are left as is and processed by the scheduler, and the result of
    submitting the job is printed to standard output. Output string can specify
    four different directives provided by "<key>:<value>" strings separated by
    pipe:

    * stdout - specifies a path to a log file that should store standard output
               of the submitted job
    * stderr - specified a path to a log file that should store error output
               of the submitted job
    * both   - specifies a path to a log file that should store joint standard
               and error outputs of the submitted job
    * return - specifies whether standard output ('stdout'), error outpout
               ('stderr'), both ('both') or none ('none') should be returned as
               a string from the job submission call.

    Specify "return" value only when schedule is used as a function called from
    another python script or function to process the result.

    Examples:

    * "stdout:processing.log"
    * "stdout:processing.output.log|stderr:processing.error.log"
    * "both:processing.log|return:true"

    Do not specify error and standard outputs both using --output parameter and
    scheduler specific options within settings string.

    SCHEDULER SPECIFICS
    ===================

    Each of the supported scheduler systems has a somewhat different way of
    specifying job parameters. Please see documentation for each of the
    supported schedulers to provide the correct settings. Below are the
    information for each of the schedulers on how to specify --settings.

    PBS settings
    ------------

    PBS uses various flags to specify parameters. Be careful that the settings
    string includes only comma separated 'key=value' pairs. Scheduler will then
    do its best to use the right flags. Specifically:

    Keys: mem, walltime, software, file, procs, pmem, feature, host,
    naccesspolicy, epilogue, prologue will be submitted using:
    "#PBS -l <key>=<value>".

    Keys: j, m, o, S, a, A, M, q, t, e will be submitted using:
    "#PBS -<key> <value>"

    Key: depend will be submitted using:

    "#PBS -W depend=<value>"

    Key: nodes is a special case. It can have up to three values separated by
    colon (":"). If there is only one value e.g. "nodes=4" it will submit:

    "#PBS -l nodes=4"

    When there are two values e.g. "nodes=4:2" it will submit:

    "#PBS -l nodes=4:ppn=2"

    When there are three values what is submitted depends on the type of the
    last value. When it is numeric, e.g. "nodes:8:4:2", it will submit:

    "#PBS -l nodes=8:ppn=4:cpus=2"

    If the last of the three values is a string, e.g. "nodes:8:4:blue", it will
    submit the last value as a self-standing key:

    "#PBS -l nodes=8:ppn=4:blue"

    LSF settings
    ------------

    For LSF the following key/value parameters are parsed as:

    * queue    -> "#BSUB -q <queue>"
    * mem      -> "#BSUB -R 'span[hosts=1] rusage[mem=<mem>]"
    * walltime -> "#BSUB -W <walltime>"
    * cores    -> "#BSUB -n <cores>"

    Keys: g, G, i, L, cwd, outdir, p, s, S, sla, sp, T, U, u, v, e, eo, o, oo
    will be submitted using:

    "#BSUB -<key> <value>"

    SLURM settings
    --------------

    For SLURM any provided key/value pair will be passed in the form:

    "#SBATCH --<key>=<value>"

    Some of the possible parameters to set are:

    partition        ... The partition (queue) to use
    nodes            ... Total number of nodes to run on
    ntasks           ... Number of tasks
    cpus-per-task    ... Number of cores per task
    time             ... Maximum wall time DD-HH:MM:SS
    constraint       ... Specific node architecture
    mem-per-cpu      ... Memory requested per CPU in MB
    mail-user        ... Email address to send notifications to
    mail-type        ... On what events to send emails


    EXAMPLE USE
    ===========

    gmri schedule command="bet t1.nii.gz brain.nii.gz" \\
                  settings="SLURM,jobname=bet1,time=03-24:00:00,ntasks=10,cpus-per-task=2,mem-per-cpu=2500,partition=pi_anticevic"

    gmri schedule command="bet {{in}} {{out}}" \\
                  replace="in:t1.nii.gz|out:brain.nii.gz" \\
                  settings="SLURM,jobname=bet1,time=03-24:00:00,ntasks=10,cpus-per-task=2,mem-per-cpu=2500,partition=pi_anticevic" \\
                  workdir="/studies/WM/Subjects/AP23791/images/structural"

    ----------------
    Written by Grega Repov≈°, 2017-06-17

    Changelog
    2017-09-30 - Grega Repovs
                 Added additional options to scheduling LSF jobs.
    2017-09-30 - Grega Repovs
                 Added options to redirect job output to log files.
    2018-10-03 - Grega Repovs
                 Added checking for validity of log file directories.
    2018-10-04 - Grega Repovs
                 Excluded log validity checking for 'return'.
    2019-03-07 - Jure Demsar
                 Python3 support.
    '''

    # --- check inputs

    if command is None and script is None:
        raise CommandError("schedule", "Missing parameter", "Either command or script need to be specified to run scheduler!")

    if command is not None and script is not None:
        raise CommandError("schedule", "Parameter conflict", "Only command or script need to be provided to run scheduler!")

    if settings is None:
        raise CommandError("schedule", "Missing parameter", "Settings need to be provided to run scheduler!")

    # --- parse settings

    try:
        setList   = [e.strip() for e in settings.split(",")]
        scheduler = setList.pop(0)
        setDict   = dict([e.strip().split("=") for e in setList])
        jobname   = setDict.pop('jobname', "schedule")
        comname   = setDict.pop('comname', "")
        jobnum    = setDict.pop('jobnum', "1")
    except:
        raise CommandError("schedule", "Misspecified parameter", "Could not parse the settings string:", settings)

    if scheduler not in ['PBS', 'LSF', 'SLURM']:
        raise CommandError("schedule", "Misspecified parameter", "First value in the settings string has to specify one of PBS, LSF, SLURM!", "The settings string submitted was:", settings)

    # --- compile command to pass

    if command is None:
        if not os.path.exists(script):
            raise CommandFailed("schedule", "File not found", "The specified script does not exist! [%s]" % (script))
        command = open(script, "r")

    if workdir is not None:
        if not os.path.exists(workdir):
            raise CommandFailed("schedule", "Folder does not exist", "The specified working directory does not exist! [%s]" % (workdir))
        command = "cd %s\n" % (workdir) + command

    if environment is not None:
        if not os.path.exists(environment):
            raise CommandFailed("schedule", "File not found", "The specified environment script does not exist! [%s]" % (environment))
        command = open(environment, "r") + "\n" + command

    # --- do search replace

    if replace is not None:
        replace = [e.strip().split(":") for e in replace.split("|")]

        for key, value in replace:
            command.replace("{{%s}}" % (key), value)


    # --- parse output

    outputs = {'stdout': None, 'stderr': None, 'both': None, 'return': None}

    if output is not None:
        for k, v in [[f.strip() for f in e.split(":")] for e in output.split("|")]:
            if not os.path.exists(os.path.dirname(v)) and k != 'return':
                raise CommandFailed("schedule", "Folder does not exist", "The specified folder for the '%s' log file does not exist! [%s]" % (k, os.path.dirname(v)), "Please check your paths!")
            outputs[k] = v

    if outputs['both'] is not None:
        outputs['stderr'] = outputs['both']
        outputs['stdout'] = outputs['both']

    # --- build scheduler commands

    sCommand = ""

    if scheduler == "PBS":
        for k, v in setDict.items():
            if k in ('mem', 'walltime', 'software', 'file', 'procs', 'pmem', 'feature', 'host', 'naccesspolicy', 'epilogue', 'prologue'):
                sCommand += "#PBS -l %s=%s\n" % (k, v)
            elif k in ('j', 'm', 'o', 'S', 'a', 'A', 'M', 'q', 't', 'e'):
                sCommand += "#PBS -%s %s\n" % (k, v)
            elif k == 'depend':
                sCommand += "#PBS -W depend=%s\n" % (v)
            elif k == 'nodes':
                v = v.split(':')
                res = 'nodes=%s' % (v.pop(0))
                if v:
                    res += ":ppn=%s" % (v.pop(0))
                if v:
                    if v[0].isnumeric():
                        res += ":gpus=%s" % (v.pop(0))
                    else:
                        res += ":" + v.pop(0)
        sCommand += "#PBS -N %s-%s#%s\n" % (jobname, comname, jobnum)
        if outputs['stdout'] is not None:
            sCommand += "#PBS -o %s\n" % (outputs['stdout'])
        if outputs['stderr'] is not None:
            sCommand += "#PBS -e %s\n" % (outputs['stderr'])
        if outputs['both']:
            sCommand += "#PBS -j oe\n"
        com = 'qsub'

    elif scheduler == "LSF":
        sCommand += "#BSUB -o %s-%s_#%s_%%J\n" % (jobname, comname, jobnum)
        for k, v in [('queue', '#BSUB -q %s\n'), ('mem', "#BSUB -R 'span[hosts=1] rusage[mem=%s]'\n"), ('walltime', '#BSUB -W %s\n'), ('cores', '#BSUB -n %s\n')]:
            if k in setDict:
                sCommand += v % (setDict[k])
        for k, v in setDict.items():
            if k in ('g', 'G', 'i', 'L', 'cwd', 'outdir', 'p', 's', 'S', 'sla', 'sp', 'T', 'U', 'u', 'v', 'e', 'eo', 'o', 'oo'):
                sCommand += "#BSUB -%s %s\n" % (k, v)
        sCommand += "#BSUB -P %s-%s\n" % (jobname, comname)
        sCommand += "#BSUB -J %s-%s#%d\n" % (jobname, comname, jobnum)
        if outputs['stdout'] is not None:
            sCommand += "#BSUB -o %s\n" % (outputs['stdout'])
        if outputs['stderr'] is not None:
            sCommand += "#BSUB -e %s\n" % (outputs['stderr'])
        com = 'bsub'

    elif scheduler == "SLURM":
        sCommand += "#!/bin/sh\n"
        sCommand += "#SBATCH --job-name=%s-%s#%s\n" % (jobname, comname, jobnum)
        for key, value in setDict.items():
            sCommand += "#SBATCH --%s=%s\n" % (key.replace('--', ''), value)
        if outputs['stdout'] is not None:
            sCommand += "#SBATCH -o %s\n" % (outputs['stdout'])
        if outputs['stderr'] is not None:
            sCommand += "#SBATCH -e %s\n" % (outputs['stderr'])
        com = 'sbatch'

    # --- run scheduler

    print("Submitting:\n------------------------------\n", sCommand + command)

    if outputs['return'] is None:
        serr = None
        sout = None
    elif outputs['return'] == 'both':
        serr = subprocess.STDOUT
        sout = subprocess.PIPE
    elif outputs['return'] == 'stderr':
        serr = subprocess.PIPE
        sout = None
    elif outputs['return'] == 'stdout':
        serr = None
        sout = subprocess.PIPE

    run = subprocess.Popen(com, shell=True, stdin=subprocess.PIPE, stdout=sout, stderr=serr, close_fds=True)
    run.stdin.write(sCommand + command)
    run.stdin.close()

    # ---- returning results

    if outputs['return'] in ['both', 'stdout']:
        result = run.stdout.read()
        return result
    elif outputs['return'] in ['stderr']:
        result = run.stderr.read()
        return result


def getSubjidFromBatchFile(filename):
    '''
    getSubjidFromBatchFile(filename)

    An internal function for reading batch.txt files. It reads the file and
    returns a list of subjects with the information on images and the additional
    parameters specified in the header.

    ---
    Written by Grega Repovs and Jure Demsar.
    '''

    if not os.path.exists(filename):
        print("\n\n=====================================================\nERROR: Batch file does not exist [%s]", file=filename)
        raise ValueError("ERROR: Batch file not found: %s" % (filename))

    s = open(filename, "r").read()
    s = s.replace("\r", "\n")
    s = s.replace("\n\n", "\n")
    s = re.sub("^#.*?\n", "", s)

    s = s.split("\n---")
    s = [e for e in s if len(e) > 10]

    subjid = []

    for sub in s:
        sub = sub.split('\n')
        sub = [e.strip() for e in sub]
        sub = [e.split("#")[0].strip() for e in sub]
        sub = [e for e in sub if len(e) > 0]

        for line in sub:
            line = [e.strip() for e in line.split(":")]

            # id line
            if len(line) == 2 and line[0] == "id":
                subjid.append(line[1])
                break

    return subjid


def getSubjidFromList(filename):
    '''
    getSubjidFromList(filename)

    An internal function for reading list files. It reads the file and
    returns a list of subjects ids.

    ---
    Written by Grega Repovs and Jure Demsar.
    '''

    if not os.path.exists(filename):
        print("\n\n=====================================================\nERROR: List file does not exist [%s]", file=filename)
        raise ValueError("ERROR: List file not found: %s" % (filename))

    subjid  = []

    with open(filename) as f:
        for line in f:
            if line.strip()[:1] == "#":
                continue

            line = [e.strip() for e in line.split(":")]

            if len(line) == 2 and line[0] == "subject id":
                subjid.append(line[1])

    return subjid


def getSubjid(listString, subjectsfolder=None):
    '''
    getSubjid(listString)

    An internal function for getting a list of subject ids.

    The provided listString can be:

    * a comma, space or pipe separated list of subject id codes,
    * a path to a batch file (identified by .txt extension),
    * a path to a *.list file (identified by .list extension).

    ---
    Written by Grega Repovs and Jure Demsar.
    '''

    listString = listString.strip()

    if re.match(".*\.list$", listString):
        subjid = getSubjidFromList(listString)

    elif os.path.isfile(listString):
        subjid = getSubjidFromBatchFile(listString)

    elif re.match(".*\.txt$", listString) or '/' in listString:
        raise ValueError("ERROR: The specified subject file is not found! [%s]!" % listString)

    else:
        subjid = [e.strip() for e in re.split(' +|,|\|', listString)]

        if subjectsfolder is not None:
            nlist = []
            for s in subjid:
                nlist += glob.glob(os.path.join(subjectsfolder, s))
            subjid = [os.path.basename(e) for e in nlist]

    return subjid


def main(args=None):
    """
    mnapContainer v0.1.0

    mnapContaiiner is a self-standing command that can run MNAP commands 
    against a Singularity or a Docker MNAP container. To run an MNAP command 
    against a conainer the basic call is:

    $ mnapContainer <mnap command> [parameters] --image="<a path to the Singularity image or a Docker container name>" [additional options]
    
    `mnap command` is any command supported by MNAP. `parameters` are any
    parameters that should be passed to the mnap command. This part is the same
    as running:

    $ mnap <mnap command> [parameters]

    from within a container or on a self-standing MNAP installation. For list of
    commands and their parameters consult MNAP online or in-line documentation.

    Additionally mnapContainer accepts the following parameters:

    Required parameter:
    -------------------

    --image     ... specifies either the path to the Singularity container image 
                    or the name of the Docker container to be used. This 
                    parameter can be omitted if the value is specified in the 
                    `MNAPCONIMAGE` environmental variable.

    Optional parameters:
    --------------------

    --script    ... If a script is to be run agains the Singularity container
                    rather than a single command, the path to the script to be
                    run is specified here. ['']

    --envars    ... If environment variables other than the default set by the
                    container are to be used, they can be specified in a pipe
                    separated string formatted as:
                    "<variable>=><value>|<variable>:<value>"
                    Note that only the variables recognized by the MNAP suite
                    will be appropriately parsed and used in the container.

    --dockeropt ... A string that lists the additional options to be used when
                    running the Docker container. If the parameter is ommited, 
                    the content of `MNAPDOCKEROPT` environment variable will
                    be used. If neither is specified, the container will be 
                    run in a detached mode with the current folder mounted as 
                    `/data` by specifying the following options:

                    '-d -v "$(pwd)":/data'                     
                    
                    The parameters are to be specified in a string exactly as 
                    they would be on a command line, e.g:

                    "-d -v /host/directory:/container/directory"

    --scheduler ... A string that specifies the details to use to submit the 
                    container job to a scheduling system. 

    --output    ... A string specifying where to redirect the standard output 
                    and error when using the scheduler. See "Redirecting 
                    output" for details!
    

    Scheduling containers
    ---------------------

    Container commands can be submitted to a scheduling system by specifying 
    the `--scheduler` parameter with a settings string. The settings string 
    should be a comma separated list of parameters. The first parameter has to 
    be the scheduler name (PBS, LSF, SLURM), the rest of the parameters are 
    key-value pairs that are to be passed as settings to the scheduler. 
    Additional parameters common to all the schedulers can be specified:

    * jobname  - the name of the job to run
    * comname  - the name of the command the job runs
    * jobnum   - the number of the job being run

    Example settings strings:

    "SLURM,jobname=hcp2,time=03-24:00:00,ntasks=10,cpus-per-task=2,mem-per-cpu=2500,partition=pi_anticevic"
    "LSF,jobname=DWIproc,jobnum=1,cores=20,mem=250000,walltime=650:00,queue=pi_anticevic"


    Scheduling multiple containers in parallel
    ------------------------------------------
    
    If the parameters provided include --cores, --scheduler, and --subjects, 
    then mnapContainer will spread the execution of the command by scheduling 
    multiple containers to run on separate nodes. Specifically, it will schedule
    each node to run a container with `cores` sessions. E.g. if 10 subjects are 
    specified and cores is set to 3, the command will schedule four containers 
    to run on four nodes. The first three containers will each run three 
    sessions in parallel, the fourth container will run the remaining session. 


    Redirecting output
    ------------------

    When running a container with a scheduler, the standard output and error
    will be saved in a folder where the command was run based on each scheduler
    system defauls. By specifying the `output` parameter the command output can
    be redirected. The parameter supports three different directives provided by
    "<key>:<value>" pairs in a pipe separated string

    * stdout - specifies a path to a log file that should store standard output
               of the submitted job
    * stderr - specified a path to a log file that should store error output
               of the submitted job
    * both   - specifies a path to a log file that should store joint standard
               and error outputs of the submitted job

    Examples:

    * "stdout:processing.log"
    * "stdout:processing.output.log|stderr:processing.error.log"
    * "both:processing.log"

    Do not specify error and standard outputs both using --output parameter and
    scheduler specific options within settings string. It is best to provide 
    full absolute paths to the desired log.

    
    Example call
    ------------

    $ mnapContainer hcp2 \\
      --subjectsfolder=/data/study/subjects \\
      --subjects=/data/study/processing/batch.txt \\
      --cores=4 \\
      --image=/singularity/mnap_suite-0_38_10.simg \\
      --scheduler="SLURM,time=2-00:00:00,ntasks=1,cpus-per-task=2,mem-per-cpu=15000,partition=pi_anticevic"

    ---
    Written by Grega Repovs and Jure Demsar.

    Changelog
    2019-03-23 - Grega Repovs
                 First complete version with documentation.
    """

    if args is None:
        args = sys.argv[1:]

    if not args:
        print(main.__doc__)
        exit()

    scheduler      = None
    image          = None
    command        = ""
    script         = None
    cores          = None
    subjects       = None
    subjectsfolder = None
    subjid         = None
    envars         = None
    dockeropt      = None
    output         = None

    for arg in args:
        if "scheduler=" in arg:
            k, scheduler = arg.split("=", 1)
        elif "image=" in arg:
            k, image = arg.split("=", 1)
        elif "envars=" in arg:
            k, envars = arg.split("=", 1)
        elif "dockeropt=" in arg:
            k, dockeropt = arg.split("=", 1)
        elif "output=" in arg:
            k, output = arg.split("=", 1)
        elif "script=" in arg:
            k, script = arg.split("=", 1)
        elif "cores=" in arg:
            k, cores = arg.split("=", 1)
            command += '%s="%s" ' % (k, cores)
        elif "subjectsfolder=" in arg:
            k, subjectsfolder = arg.split("=", 1)
            command += '%s="%s" ' % (k, subjectsfolder)
        elif "subjects=" in arg:
            k, subjects = arg.split("=", 1)
            command += '%s="%s" ' % (k, subjects)
        elif "subjid=" in arg:
            k, subjid = arg.split("=", 1)
        elif "=" in arg:
            k, v = arg.split('=', 1)
            command += '%s="%s" ' % (k, v)
        else:
            command += '%s ' % (arg)

    if image is None:
        if "MNAPCONIMAGE" in os.environ:
            image = os.environ['MNAPCONIMAGE']
        else:
            print("ERROR: No Singularity image or Docker container name specified either in the command line or as a MNAPCONIMAGE environment variable!")
            exit(1)

    # -- check for environment variables

    if envars:
        envars = [e for e in envars.split('|')]
        envars = [e.split('=>') for e in envars if '=>' in e]
    else:
        envars = []

    # -- check for docker options

    if dockeropt is None:
        if "MNAPDOCKEROPT" in os.environ:
            dockeropt = os.environ['MNAPDOCKEROPT']
        else:
            dockeropt = "-d -v \"$(pwd)\":/data"

    # run in parallel if:
    # - cores is not None
    # - cores is >1
    # - schedulers is not None
    # - subjects is not None
    subjidArray = []
    if cores is not None and int(cores) > 1 and scheduler is not None and subjects is not None:
        containers = int(cores)
        # split subjects via subjid or split existing subjid
        if subjid is None:
            subjid = getSubjid(subjects, subjectsfolder=subjectsfolder)
        else:
            subjids = getSubjid(subjects, subjectsfolder=subjectsfolder)
            subjidSplit = re.split(' +|,|\|', subjid)
            print("subjidSplit:", subjidSplit, "\nsubjid",  subjid, "\nsubjids", subjids)
            subjid = [e for e in subjids if e in subjidSplit]

        # split subjids according to cores and add to array
        start = 0
        end = len(subjid)
        chunks = int(math.ceil(end / float(cores)))
        for i in range(start, end, chunks):
            start = i
            subjidChunk = subjid[start:start+chunks]
            subjidArray.append(','.join(subjidChunk))
    else:
        # do not run parallel
        containers = 1
        # add subjid filter back if exists
        if subjid is not None:
            subjidArray.append(subjid)

    for i in range(0, containers):
        scheduleCommand = command

        # add subjid to command?
        if i < len(subjidArray):
            subjid = subjidArray[i]
            scheduleCommand += 'subjid="%s" ' % (subjid)

        # setup for Singularity
        if image.endswith(".simg") or image.endswith(".sif"):
            fid, scriptPath = tempfile.mkstemp(dir="./")
            f = os.fdopen(fid, 'w')

            for k, v in envars:
                print("export con_%s=\"%s\"" % (k, v), file=f)
            print("source /opt/mnaptools/library/environment/mnap_environment.sh", file=f)

            # --- run command or script
            if script:
                print("bash " + script, file=f)
            elif 'runTurnkey' in scheduleCommand:
                scheduleCommand = scheduleCommand.replace('runTurnkey', '')
                print("bash /opt/mnaptools/connector/functions/RunTurnkey.sh" + scheduleCommand, file=f)
            else:        
                print("bash /opt/mnaptools/connector/mnap.sh " + scheduleCommand, file=f)
            
            print("rm " + scriptPath, file=f)

            f.close()

            containerCommand = "singularity exec %s bash %s " % (image, scriptPath)

        # setup for Docker
        elif not script:
            cstring = ""

            # --> add container variables
            for k, v in envars:
                cstring += "export con_%s=\"%s\"; " % (k, v)

            if scheduleCommand == 'runTurnkey':
                scheduleCommand = scheduleCommand.replace('runTurnkey', '')
                cstring = "source /opt/mnaptools/library/environment/mnap_environment.sh; bash /opt/mnaptools/connector/functions/RunTurnkey.sh " + scheduleCommand
            else:
                cstring = "source /opt/mnaptools/library/environment/mnap_environment.sh; bash /opt/mnaptools/connector/mnap.sh " + scheduleCommand

            containerCommand = "docker container run %s %s bash -c \"%s\"" % (dockeropt, image, cstring)

        # Docker and scripts
        else:
            print("ERROR: mnapContainer can not run scripts against a Docker container!")
            return

        if scheduler:
            schedule(command=containerCommand, settings=scheduler, output=output)
        else:
            subprocess.Popen(containerCommand, shell=True)

if __name__ == "__main__":
    main()
